{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer # type: ignore\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences # type: ignore\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"../datasets/stanfordSentimentTreebank/datasetSentences.txt\"\n",
    "LABELS_PATH = \"../datasets/stanfordSentimentTreebank/sentiment_labels.txt\"\n",
    "DICTIONARY_PATH = \"../datasets/stanfordSentimentTreebank/dictionary.txt\"\n",
    "DATASPLIT_PATH = \"../datasets/stanfordSentimentTreebank/datasetSplit.txt\"\n",
    "\n",
    "MODEL_PATH = \"sentiment_analysis_model_02.keras\"\n",
    "TOKENIZER_PATH = \"tokenizer_02.pickle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATASET_PATH, sep=\"\\t\")\n",
    "train_df = train_df[[\"sentence\", \"sentence_index\"]]\n",
    "train_df.set_index(\"sentence_index\", inplace=True)\n",
    "\n",
    "split = pd.read_csv(DATASPLIT_PATH, sep=\",\")\n",
    "split = split[[\"sentence_index\", \"splitset_label\"]]\n",
    "split.set_index(\"sentence_index\", inplace=True)\n",
    "\n",
    "train_df = train_df.join(split)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(LABELS_PATH, sep=\"|\")\n",
    "df.columns = [\"phrase_id\", \"sentiment_value\"]\n",
    "df.set_index(\"phrase_id\", inplace=True)\n",
    "df.sort_index(inplace=True)\n",
    "df[\"sentiment_class\"] = df[\"sentiment_value\"].apply(lambda x: \"negative\" if x < 0.4\n",
    "                                                    else \"neutral\" if x < 0.6\n",
    "                                                    else \"positive\")\n",
    "# df.head()\n",
    "# df[\"sentiment_class\"].value_counts()\n",
    "\n",
    "dictionary = pd.read_csv(DICTIONARY_PATH, sep=\"|\", header=None)\n",
    "dictionary.columns = [\"phrase\", \"phrase_id\"]\n",
    "\n",
    "dictionary.set_index(\"phrase_id\", inplace=True)\n",
    "# dictionary[\"phrase\"] = dictionary[\"phrase\"].astype(str)\n",
    "\n",
    "# Check for non-string phrases. Convert them to strings if possible. Drop them if not.\n",
    "for i in range(len(dictionary[\"phrase\"])):\n",
    "    if type(dictionary.loc[i, \"phrase\"]) != str:\n",
    "        try:\n",
    "            dictionary.loc[i, \"phrase\"] = str(dictionary.loc[i, \"phrase\"])\n",
    "        except:\n",
    "            print(f\"Dictionary phrase {i} is not a string. Type: {type(dictionary.loc[i, \"phrase\"])} Removed.\")\n",
    "            dictionary.drop(i, inplace=True)\n",
    "\n",
    "\n",
    "dictionary[\"phrase\"] = dictionary[\"phrase\"].apply(lambda x: x.lower())\n",
    "dictionary.sort_index(inplace=True)\n",
    "\n",
    "df = df.join(dictionary, how=\"left\")\n",
    "dictionary.dropna(subset=[\"phrase\"], inplace=True)  # Remove rows with NaN phrases\n",
    "df.head()\n",
    "\n",
    "# 42077, 67853"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df[\"phrase\"]) # df[\"sentence\"]\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df[\"phrase\"]) # df[\"sentence\"]\n",
    "padded_sequences = pad_sequences(sequences, padding=\"post\")\n",
    "\n",
    "# sentiment_labels = pd.read_csv(LABELS_PATH, sep=\"|\")\n",
    "# sentiment_labels[\"sentiment class\"] = pd.cut(sentiment_labels[\"sentiment values\"], bins=[0, 0.45, 0.55, 1], labels=[\"negative\", \"neutral\", \"positive\"])\n",
    "# sentiment_labels = sentiment_labels[[\"phrase_id\", \"sentiment values\", \"sentiment class\"]]\n",
    "# sentiment_labels[1:100]\n",
    "\n",
    "# sentiment_labels[\"sentiment class\"].value_counts()\n",
    "# print(padded_sequences.shape, sentiment_labels[\"sentiment class\"].shape, dictionary_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = padded_sequences[df[\"splitset_label\"] == 1]\n",
    "# y_train = sentiment_labels[\"sentiment values\"][sentiment_labels[\"phrase_id\"].isin(df.index[df[\"splitset_label\"] == 1])]\n",
    "# y_train = np.array(y_train)\n",
    "\n",
    "\n",
    "# x_test = padded_sequences[df[\"splitset_label\"] == 2]\n",
    "# y_test = sentiment_labels[\"sentiment values\"][sentiment_labels[\"phrase_id\"].isin(df.index[df[\"splitset_label\"] == 2])]\n",
    "# y_test = np.array(y_test)\n",
    "\n",
    "x_train = padded_sequences\n",
    "y_train = pd.get_dummies(df[\"sentiment_class\"]).values\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_test = train_df[\"sentence\"][train_df[\"splitset_label\"] == 2]\n",
    "x_test = tokenizer.texts_to_sequences(x_test)\n",
    "x_test = pad_sequences(x_test, padding=\"post\")\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "y_test = df[\"sentiment_class\"][df.index.isin(train_df.index[train_df[\"splitset_label\"] == 2])]\n",
    "y_test = pd.get_dummies(y_test).values\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "# x_train, y_train, x_test, y_test = train_test_split(padded_sequences, sentiment_labels[\"sentiment values\"], test_size=0.2)\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(5000, 100))\n",
    "# model.add(Conv1D(64, 5, activation=\"relu\"))\n",
    "# model.add(GlobalMaxPooling1D())\n",
    "# model.add(Dense(32, activation=\"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "# type(x_train), type(y_train), type(x_test), type(y_test)\n",
    "\n",
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.Embedding(10000, 100),\n",
    "        keras.layers.Conv1D(64, 5, activation=\"relu\"),\n",
    "        keras.layers.GlobalMaxPooling1D(),\n",
    "        keras.layers.Dense(32, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        keras.layers.Dropout(0.7),\n",
    "        keras.layers.Dense(32, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        keras.layers.Dropout(0.6),\n",
    "        keras.layers.Dense(3, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "# type(y_pred)\n",
    "\n",
    "# def return_sentiment_class(pred):\n",
    "#     if pred > 0.66:\n",
    "#         return \"positive\"\n",
    "#     elif pred < 0.33:\n",
    "#         return \"negative\"\n",
    "#     else:\n",
    "#         return \"neutral\"\n",
    "\n",
    "# y_test_classes = [return_sentiment_class(label) for label in y_test]\n",
    "# y_pred_classes = [return_sentiment_class(label) for label in y_pred]\n",
    "\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "precision = precision_score(y_test_classes, y_pred_classes, average=\"weighted\", zero_division=1)\n",
    "recall = recall_score(y_test_classes, y_pred_classes, average=\"weighted\")\n",
    "f1 = f1_score(y_test_classes, y_pred_classes, average=\"weighted\")\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model.save(MODEL_PATH)\n",
    "with open(TOKENIZER_PATH, \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(MODEL_PATH)\n",
    "with open(TOKENIZER_PATH, \"rb\") as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "\n",
    "def predict_sentiment(sentence):\n",
    "    text_sequence = tokenizer.texts_to_sequences([sentence])\n",
    "    text_sequence = pad_sequences(text_sequence, maxlen=100, truncating=\"post\")\n",
    "\n",
    "    predicted_sentiment = model.predict(text_sequence)\n",
    "    # predicted_sentiment_class = return_sentiment_class(predicted_sentiment)\n",
    "\n",
    "    # return predicted_sentiment_class, predicted_sentiment\n",
    "    return predicted_sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict_sentiment(\"I love this movie!\"))\n",
    "print(predict_sentiment(\"I hate this movie!\"))\n",
    "print(predict_sentiment(\"This movie is okay.\"))\n",
    "print(predict_sentiment(\"This movie is the worst!\"))\n",
    "print(predict_sentiment(\"This movie is the best!\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic-ml-projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
